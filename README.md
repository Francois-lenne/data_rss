# RSS Data Processing Pipeline

A learning project focused on building an end-to-end data pipeline using Terraform, Python, and cloud data lake technologies to process and analyze RSS feed data.

## ğŸ¯ Project Objectives

This project serves as a hands-on learning experience for:
- **Infrastructure as Code**: Using Terraform to provision and manage cloud infrastructure
- **Data Processing**: Analyzing RSS feeds with Python
- **Data Engineering**: Building ETL pipelines to process and load data into a data lake
- **Cloud Technologies**: Working with GCP

## ğŸ—ï¸ Architecture Overview

```
RSS Sources â†’ Python Scraper â†’ Data Processing â†’ Data Lake Storage â†’ Analytics
                     â†‘                                  â†‘
                     â””â”€â”€â”€â”€â”€â”€â”€â”€ Terraform IaC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technologies Used

- **Infrastructure**: Terraform
- **Programming Language**: Python
- **Data Processing**: 
  - RSS feed parsing (feedparser, BeautifulSoup)
  - Data transformation (pandas)
- **Storage**: Cloud Data Lake

## ğŸ“ Project Structure

```
data_rss/
â”œâ”€â”€ terraform/              # Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf            # Main Terraform configuration
â”‚   â”œâ”€â”€ variables.tf       # Variable definitions
â”‚   â”œâ”€â”€ outputs.tf         # Output values
â”‚   â””â”€â”€ modules/           # Reusable Terraform modules
â”œâ”€â”€ src/                   # Source code
â”‚   â”œâ”€â”€ extractors/        # RSS feed extraction logic
â”‚   â”œâ”€â”€ transformers/      # Data transformation logic
â”‚   â”œâ”€â”€ loaders/           # Data lake loading logic
â”‚   â””â”€â”€ utils/             # Utility functions
â”œâ”€â”€ config/                # Configuration files
â”œâ”€â”€ tests/                 # Unit and integration tests
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md             # This file
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Terraform 1.0+
- GCP account
- Git


## ğŸ“Š Data Pipeline Components

### 1. RSS Feed Extraction
- Fetches RSS feeds from configured sources
- Parses XML/RSS content

### 2. Data Transformation
- Cleans and normalizes feed data
- Extracts relevant fields (title, description, published date, etc.)
- Enriches data with metadata

### 3. Data  Loading
- Load the strucutre data in BigQuery
- Load the unstrucutre data (R program) in google cloud storage





## ğŸƒ Running the Pipeline

### Deploy Infrastructure
```bash
cd terraform
terraform plan
terraform apply
```



### Schedule Regular Runs
For production use, consider scheduling with:
- Cron jobs
- Cloud Scheduler




## ğŸ“š Learning Resources

### Terraform
- [Terraform Documentation](https://www.terraform.io/docs)
- [Terraform Best Practices](https://www.terraform.io/docs/cloud/guides/recommended-practices)

### RSS Processing
- [Python feedparser Documentation](https://feedparser.readthedocs.io/)
- [RSS 2.0 Specification](https://www.rssboard.org/rss-specification)



## ğŸ‘¤ Author

**FranÃ§ois Lenne**
- GitHub: [@Francois-lenne](https://github.com/Francois-lenne)
- Location: Lille, France

## ğŸ“ Learning Progress

- [x] Set up project structure
- [x] Implement RSS feed parser
- [x] Create Terraform infrastructure
- [x] Build data transformation pipeline
- [x] Deploy to cloud data lake

---

**Note**: This is an educational project designed to learn about modern data engineering practices. Feel free to adapt and extend it for your own learning journey!
